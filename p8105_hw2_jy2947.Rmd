---
title: "P8105 hw2 "
author: "Jiawei Ye"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(readxl)
```

##Problem 1
The following code chunk reads the data and do some cleaning.
```{r read_clean}
data_read = read.csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>% 
  janitor::clean_names()
nyc_transit = select(data_read, line:vending, ada, -exit_only) %>% 
  mutate(entry = recode(entry,"YES" = TRUE, "NO" = FALSE))
```

The above code chunk retained variables about the station and discarded the variables about the entrances of the station. It also changed the value of `entry` variable into logical value. The dimension of the dataset is `r nrow(nyc_transit)` rows and `r ncol(nyc_transit)` columns.  

Each observation in the dataset is a subway station entrances/exits in NYC, the variables describe stations name of the entrance/exit, the routes that run through it, the latitude and logitude of the station and ways to enter each station, whether the entrance/exit has a vending allow entrance, and ADA compliance.  

The dataset is not really tidy enough. The `route` variable needs to be combined in some way.  
```{r info_nyc_transit}
nrow(distinct(nyc_transit, station_name, line))
sum(nyc_transit$ada)
vending_proportion = 100 * nrow(filter(nyc_transit, vending == "NO"))/nrow(nyc_transit)
```

The output shows that there are `r nrow(distinct(nyc_transit, station_name, line))` distinct stations. `r sum(nyc_transit$ada)` stations are ADA compliant. `r round(vending_proportion,2)`% of the entrance/exits is not vending allowed.  

```{r reformat_data}

```

##Problem 2
```{r trash_wheel}
mtw = read_excel("./data/HealthyHarborWaterWheelTotals2017-9-26.xlsx", 
                 sheet = 1, range = cell_cols("A:N")) %>% 
  janitor::clean_names() %>% 
  filter(!is.na(date))
mtw$sports_balls = round(mtw$sports_balls, digits = 0)
mtw$sports_balls = as.integer(mtw$sports_balls)
prcpt17 = read_excel("./data/HealthyHarborWaterWheelTotals2017-9-26.xlsx",
                     sheet = "2017 Precipitation", 
                     skip = 1) %>% 
  janitor::clean_names() %>% 
  filter(!is.na(month), !is.na(total)) %>% 
  mutate(year = 2017)
  
prcpt16 = read_excel("./data/HealthyHarborWaterWheelTotals2017-9-26.xlsx",
                     sheet = "2016 Precipitation",
                     skip = 1) %>%
  janitor::clean_names() %>% 
    filter(!is.na(total), !is.na(month)) %>% 
  mutate(year = 2016)
prcpt = full_join(prcpt16, prcpt17, by = "month") %>% 
  mutate(month = month.name) %>% 
  rename(total_2016 = total.x, total_2017 = total.y)
mtw2016 = filter(mtw, year == 2016) 
```

The trash wheel dataset has `r nrow(mtw)` observations. The key variable is `dumpster`, which identifies a certain dumpster.   
The precipitation dataset has `r nrow(prcpt)` observations. the total precipitation in 2017 is `r sum(prcpt17$total)`.  The median number of sports balls in 2016 is `r median(mtw2016$sports_balls)`.  

##Problem 3

The following code chunk loads data. 
```{r load_data , warning = FALSE}
devtools::install_github("p8105/p8105.datasets")
library(p8105.datasets)
data("brfss_smart2010")

```

The following code chunk cleans the data. 
```{r tidy_brfss}
tidy_brfss_smart2010 = 
  brfss_smart2010 %>% 
  janitor::clean_names() %>%
  filter(topic == "Overall Health") %>% 
  select(-class, -topic, -question, -sample_size, -c(confidence_limit_low:geo_location)) %>% 
  filter(!is.na(data_value)) %>%
  spread(response, data_value) %>% 
  janitor::clean_names() %>% 
  mutate(exce_or_vg = excellent + very_good)
```

The following code chunk prepares for the answers to the questions. 
```{r answers}
unq_loca = nrow(distinct(tidy_brfss_smart2010, locationdesc))
num_states = nrow(distinct(tidy_brfss_smart2010, locationabbr))
c_state = 
  count(tidy_brfss_smart2010, locationabbr) %>% 
  arrange(desc(n))
top_n(c_state, 1)
data_2002 = filter(tidy_brfss_smart2010, year == "2002")
m_exc = median(data_2002$excellent)
```
There are `r unq_loca` unique locations in the dataset. The number of states represented is `r num_states` therefore every state is represented. New Jersy is observed the most.  
In 2002, the median of the "Excellent" response value is `r m_exc`.  


The following code chunk creats graphs.  
```{r graphs}
ggplot(data_2002, aes(x = excellent)) +
         geom_histogram()
ny_q_rsp = 
  filter(tidy_brfss_smart2010, 
         (year >= 2002) & (year <= 2010), 
         (locationdesc == "NY - New York County") | (locationdesc == "NY - Queens County"))
ggplot(ny_q_rsp, aes(x = year, y = excellent)) + 
        geom_point(aes(color = locationdesc), size = 2)
```

